{"sparsity": {"layers.0.mlp": 0, "layers.0.self_attn": 0, "layers.1.mlp": 0, "layers.1.self_attn": 0, "layers.2.mlp": 0, "layers.2.self_attn": 0, "layers.3.mlp": 0.99, "layers.3.self_attn": 0, "layers.4.mlp": 0.99, "layers.4.self_attn": 0, "layers.5.mlp": 0.99, "layers.5.self_attn": 0, "layers.6.mlp": 0.99, "layers.6.self_attn": 0, "layers.7.mlp": 0.99, "layers.7.self_attn": 0, "layers.8.mlp": 0.99, "layers.8.self_attn": 0, "layers.9.mlp": 0.99, "layers.9.self_attn": 0, "layers.10.mlp": 0.99, "layers.10.self_attn": 0, "layers.11.mlp": 0.99, "layers.11.self_attn": 0, "layers.12.mlp": 0.99, "layers.12.self_attn": 0, "layers.13.mlp": 0.99, "layers.13.self_attn": 0, "layers.14.mlp": 0.99, "layers.14.self_attn": 0.75, "layers.15.mlp": 0.99, "layers.15.self_attn": 0.75, "layers.16.mlp": 0.99, "layers.16.self_attn": 0.75, "layers.17.mlp": 0.99, "layers.17.self_attn": 0.75, "layers.18.mlp": 0.99, "layers.18.self_attn": 0.75, "layers.19.mlp": 0.99, "layers.19.self_attn": 0.75, "layers.20.mlp": 0.99, "layers.20.self_attn": 0, "layers.21.mlp": 0.99, "layers.21.self_attn": 0.75, "layers.22.mlp": 0.99, "layers.22.self_attn": 0.75, "layers.23.mlp": 0.99, "layers.23.self_attn": 0.75, "layers.24.mlp": 0.99, "layers.24.self_attn": 0, "layers.25.mlp": 0.99, "layers.25.self_attn": 0.75, "layers.26.mlp": 0.99, "layers.26.self_attn": 0.75, "layers.27.mlp": 0.99, "layers.27.self_attn": 0.75, "layers.28.mlp": 0.99, "layers.28.self_attn": 0.75, "layers.29.mlp": 0.99, "layers.29.self_attn": 0.75, "layers.30.mlp": 0.99, "layers.30.self_attn": 0, "layers.31.mlp": 0, "layers.31.self_attn": 0, "layers.32.mlp": 0, "layers.32.self_attn": 0, "layers.33.mlp": 0, "layers.33.self_attn": 0, "layers.34.mlp": 0, "layers.34.self_attn": 0, "layers.35.mlp": 0, "layers.35.self_attn": 0}, "current_step": 0, "start_step": 0.0, "mode": "svd_8", "skip_output_tokens": true, "ffn_sparsity": "ffn=0.99x28", "qkvo_sparsity": "qkv=0.75x14", "predictor_basepath": "./spft/modules/low_rank_weights/", "skip_sink_tokens": 0, "skip_random_tokens": false, "end_step": 1, "sparse_lora_branch": false, "qk_per_head": false, "qkvo_seq_avg": false, "mlp_seq_avg": true, "sparse_output_tokens": 0, "per_device_train_batch_size": 16, "lora_target_modules": "q_proj,k_proj,v_proj,o_proj", "model_max_length": 512, "model_id": "Qwen/Qwen3-8B"}